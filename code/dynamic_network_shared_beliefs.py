# -*- coding: utf-8 -*-
"""cs261_project_simulation_copy_shared_belief.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EA4qgBIRehBHoq6_TJ0ubejRo-puUhFR
"""

import itertools
from itertools import combinations, chain

import numpy as np
import cvxpy as cp
 
def findsubsets(s, n):
    return list((map(frozenset, itertools.combinations(s, n))))


def powerset(iterable):
    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))


def max_credit_issue(belief_array,credit_limit):

  credit_issue_var = cp.Variable(belief_array.shape[0])

  ##print ("belief_array",belief_array,belief_array.shape[0])
  constraints = [credit_issue_var>=0,cp.sum(credit_issue_var)<=credit_limit]

  positive_utility = cp.sum(2*cp.power((credit_issue_var+1),0.5)-2)

  prob = cp.Problem(cp.Maximize(positive_utility-credit_issue_var@(1-belief_array)),constraints)

  prob.solve()

  return credit_issue_var.value

def gamma_decr(round): ###decreasing with round

  return 1.0/((round+1)**0.2)

no_neighs = 3

belief_array = np.array([0,0.7,0.9])
credit_limit = 10
print (max_credit_issue(belief_array,credit_limit))

##import numpy as np
import csv

"""Relevant Constants:


*   **μ ~ Uni[0,1]:** constant to partition agents into Trustworthy (μ⋅*V*) or Untrustworthy Agents ((1-μ) ⋅*V*)
*  **overall_beliefs:** belief of trustworthiness of node *u* about all nodes *V* in graph *G(i)* at round *i* 
* **rounds:** number of rounds in the game
* **filename**: path to file with list of agents




"""

default_prob = 0.3

mu = np.random.uniform()
overall_beliefs = {} 
beliefs = {}
beta = 0.3
alpha = 0.1

num_rounds = 500
num_agents = 40 # for testing purposes
##mu = np.random.randint(1,num_agents)/num_agents
##print (mu)
mu = 0.25
filename = "test2.csv" # change to agents + curr_date.csv

with open(filename, 'w') as f:
    # create the csv writer
    np.random.seed(17)
    fieldnames = ["trustworthiness", "credit_limit"]
    writer = csv.DictWriter(f, fieldnames=fieldnames)

    writer.writeheader()

    for itr in range(num_agents):
      # determine if agent is trustworthy
      # want T = mu * V and U = (1-mu) * V
      if (itr < mu*num_agents):
        trustworthiness = 1
      else:
         trustworthiness = 0
      credit_limit = np.random.randint(0, 100)

      # write agent to the csv file
      writer.writerow({fieldnames[0] : trustworthiness, fieldnames[1] : credit_limit})

"""Information about Agent *u*:


*   **trustworthiness**= 1 if trustworthy, else **trustworthiness** = 0
*   **credit_limit** ∈ ℕ: credit issuing limit of node *u* 
*   **neighbors**: neighbors of *u* at round *i*
*   **beliefs**: belief of trustworthiness of node *u* about node *v* at round *i*
*   **credit_extended**: credit extended to node *v* by node *u* at round *i*
*   **IOUs**: IOU’s that node *u* owes node *v* at round *i*

"""

class Agent:
  def __init__(self, t, c, default_prob, identity): ##neigh used for initilising set of neighbours
    self.trustworthiness = t
    self.credit_limit = c
    self.neighbors = set() # probably want this to initially be all other nodes and let it dwindle down ??
    ##self.beliefs = {} not needed as common beliefs stored
    self.credit_extended = {}
    self.IOUs = {}
    self.default_prob = default_prob
    self.identifier = identity


    ##self.total_transaction = 0
    ##self.transaction = {}

"""Establish **credit_network = (agents, ties)**


1.   Define trustworthy and untrustworthy agents
2.   Keep track of history of transactions: 
    * **transactions**: node *u* honours IOU to node *v* at round *i*

initialize agents with their trustworthiness and their defined credit limit \\
-> are ties existing initially or should that be done at random in the first round???
"""

def process_agents(filename):
  agents = []
  with open(filename, 'r') as file:
    csvreader = csv.reader(file)
    header = next(csvreader)
    count = 0
    for row in csvreader:
        agent = Agent(t=int(row[0]), c=int(row[1]), default_prob=default_prob, identity=count)
        agents.append(agent)
        count += 1

  file.close()

  ###agent.beliefs = {}
  ##hat_mu = np.random.uniform(0,1)
  hat_mu = 0.5

  print ("Initialised with probability",hat_mu)
  
  for agent in agents:
    agent.neighbors = [a for a in agents if a != agent]
    beliefs[agent] = hat_mu
    # agent.beliefs[agent] = [mu for a in agents if a != agent] ###initial beliefs
  ##beliefs = {a : mu for a in agents}
  ##overall_beliefs = {}

  return agents #list of Agent objects

agents = process_agents(filename)


ties = {agent: {neighbor : 0 for neighbor in agents if neighbor != agent} for agent in agents} # dictionary (agent -> dictionary (agent -> int that is initially 0))
print ("ties",ties)

credit_network = (agents, ties)

# history of defaults and transactions for each agent in each round
transactions = [{agent: {neighbor : 0 for neighbor in agent.neighbors} for agent in agents} for _ in range(num_rounds)] # list of dictionaries, index i represents IOUs exchanged in round i
defaults = [{agent: {neighbor : 0 for neighbor in agent.neighbors} for agent in agents} for _ in range(num_rounds)] # list of dictionaries, index i represents who defaulted on round i

"""**Assigning Trust** \\
*Assumptions*: each neighbor in trustworthy. \\
For each agent, we establish how much credit we want to extend to each neighbor. If we extend credit, we can establish a tie for agent to its neighbor in our graph. Then, we record the IOUs exchanged between agent and its neighbor.

sum of credit issued amongst all neighbors is bounded by credit_limit

case where we issue most than we have, convex minimizations -> software cvxpy
"""

def assign_trust(agents,beliefs):
  IOUs_exchanged = {}
  ##print ("beliefs inside finction",beliefs)
  ##transactions_no_dict = {}
  for agent in agents:
    
    ##print ("Belief inside",agent.beliefs)


    belief_array = np.array([beliefs[neigh] for neigh in agents if agent != neigh]).flatten()

    ##print ("belief array",belief_array)
    neigh_array = np.array([neigh for neigh in agents if agent != neigh]).flatten()

    ##print ("Belief array",belief_array,type(belief_array),belief_array.shape)
    ###transaction_temp_dict = {}
    for neigh in agents:
      if (neigh != agent):
        IOUs_exchanged[(agent,neigh)] = 0 ###initialising all IOUs excahnge by 0

    credit_assn_array = max_credit_issue(belief_array,agent.credit_limit)

    ##print ("credit assign",credit_assn_array)
    
    for index in range(belief_array.size): ###basically all neighbours

      neighbor = neigh_array[index]

      ##assigned_credit = np.random_integers(0, agent.credit_limit) #CHANGE: want to maximize by add some randomness
      assigned_credit = credit_assn_array[index]
      ##print ("ties",ties)
      if (assigned_credit != 0): 
        ties[agent][neighbor] = 1 # establish a tie between agent u and its neighbor agent v
        ##transaction_temp_dict[neighbor] = 1
      else: 
        ties[agent][neighbor] = 0 # TODO: should we remove the neighbor from our list if we don't extend credit to them?
        ##transaction_temp_dict[neighbor] = 0
      IOUs_exchanged[(agent,neighbor)] = assigned_credit*beta
      ##transaction_temp_dict[neighbor] = 1
    ##transactions_dict[agent] = transaction_temp_dict

    

  
  ##print ("IOUs_exchanged",IOUs_exchanged)
  return IOUs_exchanged

a = np.array([1,6,9])
a.size

def to_default_not():

  

  pass

"""deciding to default
  if you are untrustworthy \\
    1. flip a coin; heads = default, tails = honor
    2. default with probability overall_beliefs[agent]
    3. default with probability overall_beliefs[agent] and maximize gain (default on person w highest credit issued)
"""

def reclaim_IOUs(agents, IOUs_exchanged):
  defaults = {}
  for agent,neighbor in IOUs_exchanged: 
    ##for neighbor in neighbors:
      # if agent defaults on the IOU to its neighbor, record 1 else 0
      if (agent.trustworthiness) : # if agent is trustworthy, always honour transaction
        defaults[(agent,neighbor)] = 0
      elif (IOUs_exchanged[(agent,neighbor)] >= IOUs_exchanged[(neighbor,agent)] or IOUs_exchanged[(neighbor,agent)] <=1e-7): ###agent has paid more than it is owed so no default
        defaults[(agent,neighbor)] = 0

      else:
        total_IOUs_owed = sum([max(-IOUs_exchanged[(agent,neighbor)] + IOUs_exchanged[(neighbor,agent)],0) for neighbor in agents if neighbor != agent]) ##considering those neighbours whom it owes IOUs

        ##print ("total IOUs owed by",agent.identifier, " is ",total_IOUs_owed)
        ##defaults[(agent,neighbor)] = np.random.uniform(0,agent.default)

        temp = np.random.uniform()

        # defaulting is contingent on whether the gain from
        # defaulting on the previous transactions of round i 
        # is greater than the future expected (marginal)
        # utility of maintaining a tie with neighbor v





        ##default_gain, expected_tie_gain = calculate_gain()
        if (temp<agent.default_prob*(-IOUs_exchanged[(agent,neighbor)] + IOUs_exchanged[(neighbor,agent)])/total_IOUs_owed): ###probability of defaulting by an agent
          defaults[(agent,neighbor)] = 1
          print ("Agent",agent.identifier,"defaulted to",neighbor.identifier)
        else: defaults[(agent,neighbor)] = 0
  return defaults

np.random.uniform(0,0.3)

dict = {}
dict[(1,2)] = 7
for i,j in dict:
  print (i)

"""updating beliefs:

  - if someone defaults, we never want to extend credit to them again

  thought:
```
if (defaults[agent][neighbor]): 
  agent.neighbors.remove(neighbor)
  ties[agent][neighbor] = 0
```



"""

np.average(np.array([1,2,5]))

from numpy.random.mtrand import gamma
def update_beliefs(round,beliefs):
  # need to update beliefs about each neighbor and overall belief about V

  # overall_beliefs = {}
  belief_individual = {} 
  ##for agent in agents:
    
    
    

    ###net_transactions_no = len(transactions[round][agent])

  """

    net_transactions_no = 0 ###counting number of transactions till round t
    net_default_no = 0
    for itr in range(round):
     for i in transactions[round]:
      if agent == i[0] and transactions[round][i] > 0:
        net_transactions_no += 1
     for j in defaults[round]:
       if agent == j[1] and defaults[round][j] == 1:
        net_default_no += 1
  """

  overall_beliefs[round] = np.average([beliefs[neighbour] for neighbour in agents]) ##avg of all beliefs


    ##overall_beliefs[agent][round] = ((mu+alpha*(net_transactions_no-net_default_no))/(1+alpha*(net_transactions_no)) ) ###weight to initial belief and weight to the number of transactions successfully completed.
    ####no of trustworthy transactions###

  if (overall_beliefs[round]<-1e-10):
      print ("Beliefs",overall_beliefs[round])

    ##print ("Overall beliefs",overall_beliefs)
  belief_individual_temp = {}
  for neighbor in agents:
      ##if (neighbor != agent):
  
        if (not (np.all([not defaults[itr][(neighbor,agent)]for itr in range(round+1) for agent in agents if neighbor != agent]))):
        ##if (neighbor in agent.neighbors): 
          ##  agent.neighbors.remove(neighbor)
          ##ties[agent][neighbor] = 0
          ##ties[neighbor][agent] = 0


          belief_individual_temp[neighbor] = 0 ###neighbor defaulted to someone.

        else:  
          belief_individual_temp[neighbor] = (gamma_decr(round))*overall_beliefs[round] + 1-gamma_decr(round)

          ###print ("Computed val",(gamma_decr(round))*overall_beliefs[agent] + 1-gamma_decr(round),"gamma_decr",gamma_decr(round),"overall belief",overall_beliefs[agent])
    ##belief_individual[agent] = belief_individual_temp

    ##print ("belief_individual_temp",belief_individual_temp)

    
  return belief_individual_temp







  pass

a = [True,False,False]
np.all(a)

"""TODO: decide what relevant information we want to extract from the game"""

import random

def get_random_color():
  random_number = random.randint(0,16777215) 
  hex_number = str(hex(random_number)) 
  hex_number ='#'+ hex_number[2:]
  return hex_number

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('seaborn-whitegrid')

def get_plot(x, y, title):
  plt.scatter(x, y)
  plt.plot(x, y)
  plt.title(title)
  plt.show()

def plot_game_summary():
  fig = plt.figure()
  ax = plt.axes()
  i=0
  # plt.plot([i for i in range(num_rounds)], [i for i in reversed(range(num_rounds))])
  for agent in agents:
    x = [i for i in range(num_rounds)]
    y = overall_beliefs[agent]
    # color = get_random_color()
    # lw = random.uniform(0,5)
    get_plot(x,y,"agent " + str(i) + ": OVERALL BELIEFS")
    i+=1

"""https://towardsdatascience.com/graph-visualisation-basics-with-python-part-ii-directed-graph-with-networkx-5c1cd5564daa """

import matplotlib.pyplot as plt
import networkx as nx

def weighted_graph(round):

  print("GRAPH OF INDIVIDUAL BELIEFS: ROUND ", round)

  G = nx.Graph()

  agent_labels = {}
  i = 0
  for agent in agents:
    agent_labels[str(i)] = agent
    i+=1
  
  edges = []

  for i in range(len(agents)):
    for j in range(len(agents)):
      if i != j: edges.append((str(i),str(j)))

  for e in edges:
    agent = agent_labels[e[0]]
    neighbor = agent_labels[e[1]]
    edge_label = str('%.4f' % agent.beliefs[neighbor])
    G.add_edge(e[0], e[1], weight = float(edge_label))

  elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d["weight"] > 0.5]
  esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d["weight"] <= 0.5]

  pos = nx.spring_layout(G, seed=len(agents), k=0.5)  # positions for all nodes - seed for reproducibility

  # nodes
  nx.draw_networkx_nodes(G, pos, node_size=700)

  # edges
  nx.draw_networkx_edges(G, pos, edgelist=elarge, width=6)
  nx.draw_networkx_edges(
      G, pos, edgelist=esmall, width=6, alpha=0.5, edge_color="b", style="dashed"
  )
  
  plt.figure(figsize=(10,6))
  # node labels
  nx.draw_networkx_labels(G, pos, font_size=20, font_family="sans-serif")
  # edge weight labels
  edge_labels = nx.get_edge_attributes(G, "weight")
  nx.draw_networkx_edge_labels(G, pos, edge_labels)

  ax = plt.gca()
  ax.margins(0.08)
  plt.axis("off")
  
  plt.title("ROUND " + str(round))
  plt.tight_layout()
  plt.show()

  # nodes = np.arange(0, len(agents)).tolist()

  # G.add_nodes_from(nodes)

def print_game_statistics():
  s = "\n *"
  for i in range(50): s += "*"
  s+= "\n"
  print(s)
  print("Number of players: ", num_agents)
  print("Number of Rounds: ", num_rounds)


  print("plotting overall beliefs")
  plot_game_summary()

def plot_individual_beliefs(agent, agent_belief_history):

  agent_labels = {}
  i = 0
  for a in agents:
    agent_labels[a] = i
    i+=1

  title = "agent " + str(agent_labels[agent]) + ": INDIVIDUAL"
  x = [i for i in range(num_rounds)]

  y = {}
  for a in agents:
    if a == agent: continue
    y[a] = np.zeros(num_rounds)

  for round_beliefs in agent_belief_history:

    for n in round_beliefs.keys():
      np.append(y[n], round_beliefs[n])

  for n in y.keys():
    plt.scatter(x, y[n])
    plt.plot(x, y[n], label = "agent " + str(agent_labels[n]))

  plt.legend()
  plt.title(title)
  plt.show()



def plot_weighted_graph(history_of_indiv_beliefs):
  i = 0
  nodes = len(agents)
  for agent in history_of_indiv_beliefs.keys():
    agent_belief_history = history_of_indiv_beliefs[agent]
    plot_individual_beliefs(agent, agent_belief_history)

    num_neighbors = len(agent_belief_history[0].keys())
    print("NUM NEIGHBORS FOR AGENT ", i)
    print(str(num_neighbors))
    i+=1


def plot_weighted_graph_shared_belief(history_of_indiv_beliefs):

  
  for agent in agents:
    belief_agent = []

    for round in range(num_rounds):
      belief_agent.append(history_of_indiv_beliefs[round][agent])
    
    plt.plot(range(num_rounds),belief_agent,label = "Global belief on agent" + str(agent.identifier))

    plt.legend()
    ###plt.title()
    plt.show()

##num_rounds = 40
history_of_indiv_beliefs = [] ###just a global functio now

def play_game(beliefs): ###passing the dictionary beliefs

  
  ##for agent in agents:
    ##history_of_indiv_beliefs[agent] = []

  print ("beliefs",beliefs)

  for round in range(num_rounds):

    print ("round",round)
    
    # step 0
    IOUs_exchanged = assign_trust(agents,beliefs.copy())
    transactions[round] = IOUs_exchanged

    # step 1
    defaults[round] = reclaim_IOUs(agents, IOUs_exchanged)
    ##update_beliefs(agents, overall_beliefs)
    beliefs = update_beliefs(round,beliefs.copy())

    ##print ("beliefs after round",round,beliefs)

    ##for agent in agents:
    ##beliefs= curr_belief
    history_of_indiv_beliefs.append(beliefs)
    ##weighted_graph(round)
    ##print ("curr_belief after round",round,curr_belief)
    
  
  ##print_game_statistics()
  plot_weighted_graph_shared_belief(history_of_indiv_beliefs)
  return beliefs


print ("beliefs",beliefs)
final_belief = play_game(beliefs)

##for agent in final_belief:
belief_ind = final_belief
  ##if (agent.trustworthiness == 0):
    ##for neigh in belief_ind:
      ##if (neigh.t == 0):
print ("Global trust"," on ", "credit_limit", [(neigh.identifier,neigh.trustworthiness,belief_ind[neigh]) for neigh in belief_ind])
  ##else:
###        print ("Trust by trustorthy agent",agent.identifier," on ", "credit_limit",agent.credit_limit, [(neigh.identifier,neigh.trustworthiness,belief_ind[neigh]) for neigh in belief_ind])
     
##print (play_game)

plt.plot(range(400),[overall_beliefs[round] for round in range(400)])

belief_array_25 = [overall_beliefs[round] for round in range(400)]
print (belief_array_25)

belief_array_75 = [0.5, 0.4375, 0.4337680119240407, 0.4636427421373085, 0.4896516977093894, 0.5040879432858626, 0.5064184848378379, 0.4991578340050305, 0.5021755499703776, 0.5094036779186761, 0.5178409855558638, 0.5261417949790822, 0.5337911737138151, 0.5406595833178583, 0.5467781894465148, 0.5522330057529908, 0.557119046357435, 0.5615229469492189, 0.5655181553135963, 0.5691651305859022, 0.5725131794179606, 0.5756025484218925, 0.5784662845492047, 0.5811317461627702, 0.5836217847289201, 0.5859556560663737, 0.5881497218424405, 0.5902179921813454, 0.5921725487512786, 0.5940238777715944, 0.595781134679054, 0.5974523564823208, 0.5990446336808702, 0.6005642506185793, 0.6020168009605894, 0.6034072833875646, 0.6047401814255156, 0.6060195304534688, 0.6072489742722876, 0.6084318131173205, 0.6095710446136865, 0.6106693988760722, 0.611729368723374, 0.6127532357965345, 0.6137430932239185, 0.6147008653637992, 0.6156283250615207, 0.6165271087846624, 0.617398729939337, 0.6182445906216361, 0.6190659920180173, 0.6198641436352667, 0.6206401715132746, 0.6213951255510743, 0.6221299860575968, 0.6228456696226827, 0.6235430343905095, 0.6242228848063067, 0.6248859758976747, 0.625533017143703, 0.6261646759781702, 0.6267815809671916, 0.6273843246966131, 0.6279734664000937, 0.6285495343550614, 0.6291130280704837, 0.6296644202875762, 0.6302041588121355, 0.6307326681950542, 0.631250351275715, 0.6317575906013458, 0.6322547497339891, 0.6327421744554916, 0.6332201938798228, 0.6336891214810568, 0.6341492560445043, 0.6346008825477121, 0.6350442729773876, 0.6354796870877031, 0.6359073731049024, 0.6363275683826674, 0.6367405000122701, 0.6371463853911679, 0.6375454327533572, 0.6379378416644981, 0.6383238034845552, 0.63870350180045, 0.6390771128310057, 0.6394448058062636, 0.639806743323074, 0.640163081678702, 0.6405139711840407, 0.6408595564578985, 0.6411999767036967, 0.6415353659698143, 0.6418658533947161, 0.6421915634379026, 0.6425126160976482, 0.6428291271164148, 0.6431412081747581, 0.6434489670744851, 0.6437525079117616, 0.6440519312408183, 0.6443473342288535, 0.6446388108026904, 0.6449264517877048, 0.6452103450394988, 0.6454905755687694, 0.6457672256597834, 0.646040374982843, 0.646310100701101, 0.64657647757206, 0.6468395780440658, 0.6470994723480837, 0.6473562285850324, 0.6476099128089269, 0.6478605891060629, 0.6481083196704728, 0.6483531648758506, 0.6485951833441475, 0.6488344320110142, 0.6490709661882643, 0.6493048396235148, 0.6495361045571573, 0.6497648117767982, 0.6499910106693008, 0.6502147492705532, 0.6504360743130811, 0.6506550312716115, 0.6508716644066947, 0.6510860168064808, 0.6512981304267413, 0.651508046129225, 0.6517158037184271, 0.651921441976852, 0.6521249986988398, 0.6523265107230254, 0.6525260139634984, 0.6527235434397212, 0.6529191333052655, 0.6531128168754232, 0.6533046266537399, 0.653494594357526, 0.6536827509423867, 0.6538691266258182, 0.6540537509099109, 0.6542366526032011, 0.6544178598417052, 0.6545974001091776, 0.6547753002566202, 0.6549515865210823, 0.655126284543775, 0.6552994193875351, 0.6554710155536633, 0.6556410969981614, 0.655809687147399, 0.6559768089132274, 0.6561424847075685, 0.6563067364564972, 0.6564695856138385, 0.656631053174302, 0.656791159686166, 0.6569499252635371, 0.6571073695981958, 0.6572635119710485, 0.6574183712631985, 0.6575719659666543, 0.6577243141946848, 0.6578754336918395, 0.6580253418436446, 0.6581740556859852, 0.6583215919141903, 0.6584679668918278, 0.6586131966592218, 0.6587572969417028, 0.6589002831575999, 0.6590421704259859, 0.6591829735741828, 0.6593227071450366, 0.6594613854039716, 0.6595990223458287, 0.6597356317015, 0.6598712269443621, 0.6600058212965191, 0.6601394277348599, 0.6602720589969363, 0.6604037275866702, 0.6605344457798925, 0.6606642256297226, 0.660793078971792, 0.6609210174293185, 0.6610480524180355, 0.6611741951509802, 0.6612994566431478, 0.6614238477160151, 0.6615473790019367, 0.6616700609484187, 0.6617919038222764, 0.6619129177136742, 0.6620331125400585, 0.6621524980499798, 0.6622710838268147, 0.6623888792923853, 0.6625058937104823, 0.6626221361902931, 0.6627376156897407, 0.6628523410187326, 0.6629663208423252, 0.6630795636838045, 0.6631920779276882, 0.6633038718226478, 0.6634149534843574, 0.6635253308982676, 0.6636350119223101, 0.6637440042895321, 0.6638523156106647, 0.663959953376628, 0.6640669249609705, 0.6641732376222492, 0.6642788985063517, 0.6643839146487587, 0.6644882929767524, 0.66459204031157, 0.6646951633705054, 0.6647976687689584, 0.6648995630224372, 0.6650008525485095, 0.6651015436687088, 0.6652016426103948, 0.6653011555085702, 0.665400088407653, 0.6654984472632092, 0.6655962379436431, 0.6656934662318491, 0.6657901378268255, 0.66588625834525, 0.6659818333230196, 0.6660768682167546, 0.6661713684052695, 0.6662653391910093, 0.6663587858014536, 0.666451713390489, 0.6665441270397515, 0.6666360317599379, 0.6667274324920878, 0.6668183341088387, 0.6669087414156525, 0.6669986591520137, 0.6670880919926049, 0.6671770445484518, 0.6672655213680486, 0.6673535269384552, 0.6674410656863717, 0.6675281419791915, 0.6676147601260295, 0.66770092437873, 0.6677866389328526, 0.6678719079286382, 0.667956735451953, 0.6680411255352146, 0.6681250821582967, 0.6682086092494176, 0.6682917106860083, 0.6683743902955628, 0.668456651856472, 0.6685384990988403, 0.6686199357052847, 0.6687009653117179, 0.6687815915081166, 0.6688618178392733, 0.6689416478055333, 0.6690210848635171, 0.6691001324268276, 0.6691787938667451, 0.6692570725129057, 0.66933497165397, 0.6694124945382756, 0.6694896443744771, 0.6695664243321763, 0.6696428375425367, 0.6697188870988889, 0.6697945760573222, 0.6698699074372663, 0.669944884222061, 0.6700195093595163, 0.6700937857624593, 0.670167716309274, 0.6702413038444284, 0.6703145511789925, 0.6703874610911476, 0.6704600363266842, 0.6705322795994919, 0.67060419359204, 0.6706757809558492, 0.6707470443119545, 0.6708179862513595, 0.6708886093354828, 0.6709589160965954, 0.6710289090382523, 0.6710985906357129, 0.6711679633363566, 0.6712370295600903, 0.6713057916997476, 0.6713742521214818, 0.6714424131651524, 0.6715102771447026, 0.6715778463485327, 0.6716451230398653, 0.6717121094571048, 0.6717788078141901, 0.6718452203009415, 0.6719113490834016, 0.67197719630417, 0.6720427640827321, 0.6721080545157834, 0.6721730696775463, 0.6722378116200831, 0.6723022823736032, 0.6723664839467645, 0.6724304183269704, 0.6724940874806615, 0.6725574933536028, 0.6726206378711646, 0.672683522938601, 0.6727461504413222, 0.6728085222451623, 0.6728706401966427, 0.6729325061232327, 0.6729941218336034, 0.6730554891178784, 0.6731166097478815, 0.6731774854773789, 0.6732381180423179, 0.6732985091610618, 0.6733586605346209, 0.6734185738468806, 0.6734782507648239, 0.6735376929387523, 0.6735969020025026, 0.6736558795736588, 0.6737146272537641, 0.6737731466285247, 0.6738314392680147, 0.6738895067268758, 0.6739473505445138, 0.6740049722452925, 0.6740623733387243, 0.6741195553196586, 0.6741765196684655, 0.6742332678512188, 0.6742898013198746, 0.6743461215124482, 0.6744022298531869, 0.6744581277527427, 0.6745138166083388, 0.6745692978039368, 0.6746245727104001, 0.6746796426856534, 0.6747345090748429, 0.6747891732104911, 0.6748436364126521, 0.6748978999890609, 0.6749519652352841, 0.6750058334348669, 0.6750595058594768, 0.6751129837690475, 0.6751662684119186, 0.6752193610249744, 0.6752722628337802, 0.6753249750527169, 0.675377498885114, 0.6754298355233789, 0.6754819861491262, 0.6755339519333053, 0.6755857340363242, 0.6756373336081731, 0.6756887517885459, 0.6757399897069604, 0.6757910484828749, 0.6758419292258054, 0.6758926330354406, 0.6759431610017543, 0.6759935142051167, 0.6760436937164046, 0.6760937005971099, 0.676143535899446, 0.6761932006664525, 0.6762426959321007, 0.6762920227213944, 0.676341182050472, 0.676390174926705, 0.676439002348797, 0.6764876653068799, 0.6765361647826105, 0.6765845017492635, 0.6766326771718252, 0.6766806920070845, 0.676728547203724, 0.6767762437024087, 0.6768237824358746, 0.6768711643290144, 0.6769183902989642, 0.6769654612551875, 0.6770123780995586, 0.6770591417264447, 0.6771057530227876, 0.677152212868183, 0.6771985221349599, 0.6772446816882586, 0.6772906923861075, 0.6773365550794994, 0.6773822706124657, 0.6774278398221512, 0.6774732635388858, 0.6775185425862584, 0.6775636777811865, 0.6776086699339866, 0.6776535198484444, 0.6776982283218816, 0.6777427961452253, 0.6777872241030726, 0.6778315129737581, 0.6778756635294176, 0.6779196765360535, 0.6779635527535967, 0.67800729293597, 0.6780508978311491, 0.6780943681812248, 0.6781377047224615, 0.6781809081853579, 0.6782239792947049, 0.678266918769644, 0.6783097273237239, 0.6783524056649581, 0.6783949544958797, 0.6784373745135964, 0.6784796664098455, 0.6785218308710478, 0.67856386857836, 0.6786057802077275, 0.6786475664299361, 0.6786892279106633, 0.6787307653105289, 0.6787721792851448, 0.6788134704851639, 0.6788546395563297, 0.6788956871395239, 0.6789366138708134, 0.6789774203814986, 0.6790181072981589, 0.6790586752426987, 0.6790991248323928, 0.6791394566799311, 0.6791796713934634, 0.6792197695766417, 0.6792597518286652, 0.6792996187443217, 0.6793393709140302, 0.6793790089238826, 0.679418533355685, 0.6794579447869984, 0.6794972437911786, 0.6795364309374166, 0.6795755067907772, 0.6796144719122383, 0.6796533268587295, 0.6796920721831695, 0.679730708434504, 0.6797692361577429, 0.6798076558939965, 0.6798459681805121, 0.6798841735507102, 0.6799222725342184, 0.6799602656569089, 0.6799981534409311, 0.6800359364047459, 0.6800736150631613, 0.680111189927364, 0.6801486615049533, 0.6801860302999736, 0.6802232968129474, 0.6802604615409058, 0.6802975249774221, 0.6803344876126411, 0.6803713499333117, 0.6804081124228167, 0.680444775561203, 0.6804813398252112, 0.6805178056883063, 0.6805541736207061, 0.6805904440894102, 0.680626617558229, 0.6806626944878112, 0.6806986753356732, 0.6807345605562254, 0.6807703506008, 0.680806045917679, 0.6808416469521192, 0.680877154146381, 0.6809125679397522]
belief_array_50 = [0.5, 0.45, 0.3648380331309922, 0.2940774544469237, 0.2673811821217032, 0.25795702876581944, 0.26479213662424367, 0.27599832048730577, 0.27422693982341134, 0.26615809189523987, 0.2684885291969713, 0.2735811355444434, 0.27903633279334283, 0.28417849685085217, 0.2888703938372702, 0.2931285719912551, 0.2970044883629874, 0.3005505824962531, 0.30381228176308095, 0.30682734824675395, 0.30962696877125284, 0.3122370226983552, 0.3146791591900975, 0.3169716451078053, 0.31913002059645956, 0.321167606791278, 0.3230959022096015, 0.32492489531313345, 0.32666331343445637, 0.32831882290244085, 0.32989819135036946, 0.33140742042429194, 0.33285185510607296, 0.3342362743998486, 0.33556496704617134, 0.3368417951172029, 0.3380702477337839, 0.33925348667815697, 0.3403943853168374, 0.3414955619694656, 0.34255940864166623, 0.3435881158684535, 0.34458369427878954, 0.345547993383448, 0.34648271800128316, 0.34738944266872473, 0.34826962432027075, 0.3491246134812017, 0.3499556641755721, 0.3507639427210919, 0.3515505355564882, 0.3523164562253165, 0.3530626516221469, 0.3537900075919328, 0.35449935396066534, 0.355191469064689, 0.3558670838369765, 0.3565268855009444, 0.3571715209158213, 0.3578015996119547, 0.3584176965496348, 0.359020354630862, 0.3596100869899218, 0.3601873790855426, 0.36075269061473736, 0.361306457266109, 0.36184909232837537, 0.36238098816810893, 0.36290251758913616, 0.3634140350846977, 0.3639158779922742, 0.3644083675599421, 0.36489180993220127, 0.3653664970624009, 0.365832707558168, 0.3662907074656092, 0.36674075099748266, 0.3671830812100353, 0.36761793063275283, 0.3680455218548616, 0.368466068072072, 0.3688797735967234, 0.3692868343342064, 0.3696874382282819, 0.37008176567767737, 0.3704699899261398, 0.37085227742792826, 0.37122878819056576, 0.3715996760965089, 0.37196508920526367, 0.37232517003733945, 0.3726800558413286, 0.3730298788452867, 0.37337476649350165, 0.3737148416696471, 0.3740502229072432, 0.37438102458827305, 0.3747073571307371, 0.37502932716587356, 0.3753470377057119, 0.3756605883015802, 0.37597007519414327, 0.3762755914555004, 0.37657722712384056, 0.37687506933111214, 0.3771692024241342, 0.37745970807954665, 0.37774666541296587, 0.37803015108269367, 0.3783102393882961, 0.3785870023643524, 0.3788605098696528, 0.3791308296721059, 0.3793980275295976, 0.3796621672670296, 0.3799233108497502, 0.38018151845357595, 0.38043684853159276, 0.38068935787790636, 0.3809391016885124, 0.38118613361943454, 0.38143050584227767, 0.38167226909733076, 0.3819114727443476, 0.38214816481112435, 0.38238239203998636, 0.38261419993229184, 0.3828436327910506, 0.3830707337617526, 0.3832955448714954, 0.3835181070664929, 0.3837384602480465, 0.3839566433070501, 0.3841726941571022, 0.3843866497662901, 0.3845985461877086, 0.384808418588774, 0.38501630127938846, 0.3852222277390078, 0.38542623064266457, 0.38562834188599204, 0.3858285926092957, 0.38602701322071464, 0.3862236334185136, 0.38641848221254377, 0.38661158794490935, 0.38680297830987453, 0.3869926803730439, 0.38718072058984687, 0.38736712482335756, 0.38755191836147607, 0.3877351259335005, 0.3879167717261136, 0.3880968793988091, 0.3882754720987811, 0.3884525724752975, 0.3886282026935808, 0.38880238444821347, 0.3889751389760894, 0.38914648706892796, 0.38931644908536966, 0.38948504496266834, 0.38965229422799685, 0.3898182160093813, 0.3899828290462775, 0.3901461516998042, 0.39030820196264626, 0.39046899746863983, 0.3906285555020518, 0.39078689300656544, 0.39094402659398264, 0.3910999725526538, 0.391254746855645, 0.3914083651686526, 0.39156084285767434, 0.3917121949964447, 0.39186243637364604, 0.3920115814998999, 0.3921596446145481, 0.3923066396922329, 0.39245258044927855, 0.39259748034988706, 0.3927413526121496, 0.3928842102138833, 0.39302606589829747, 0.39316693217949705, 0.3933068213478266, 0.3934457454750616, 0.3935837164194531, 0.39372074583062766, 0.3938568451543514, 0.3939920256371586, 0.39412629833085366, 0.3942596740968855, 0.39439216361060425, 0.3945237773653988, 0.39465452567672293, 0.394784418686012, 0.394913466364493, 0.39504167851689287, 0.39516906478504776, 0.3952956346514164, 0.39542139744249993, 0.39554636233217166, 0.3956705383449204, 0.3957939343590088, 0.3959165591095487, 0.39603842119149946, 0.39615952906258645, 0.39627989104614736, 0.39639951533390416, 0.3965184099886664, 0.3966365829469649, 0.396754042021621, 0.39687079490425026, 0.3969868491677043, 0.39710221226845344, 0.3972168915489084, 0.39733089423968726, 0.39744422746182595, 0.3975568982289357, 0.3976689134493073, 0.3977802799279664, 0.39789100436867775, 0.3980010933759034, 0.398110553456713, 0.3982193910226496, 0.3983276123915518, 0.3984352237893328, 0.39854223135171807, 0.39864864112594245, 0.3987544590724089, 0.39885969106630803, 0.3989643428992009, 0.3990684202805661, 0.3991719288393112, 0.39927487412525037, 0.3993772616105479, 0.3994790966911308, 0.3995803846880688, 0.3996811308489234, 0.3997813403490682, 0.39988101829297906, 0.39998016971549655, 0.40007879958306036, 0.40017691279491724, 0.40027451418430254, 0.40037160851959597, 0.400468200505453, 0.40056429478391137, 0.4006598959354754, 0.4007550084801748, 0.40084963687860364, 0.40094378553293575, 0.40103745878791947, 0.4011306609318517, 0.4012233961975305, 0.40131566876318986, 0.4014074827534141, 0.40149884224003207, 0.4015897512429964, 0.4016802137312411, 0.4017702336235244, 0.40185981478925276, 0.40194896104928973, 0.4020376761767469, 0.40212596389776073, 0.4022138278922524, 0.4023012717946733, 0.4023882991947354, 0.40247491363812776, 0.40256111862721866, 0.40264691762174304, 0.4027323140394781, 0.4028173112569052, 0.4029019126098577, 0.40298612139415846, 0.40306994086624337, 0.4031533742437735, 0.40323642470623566, 0.4033190953955314, 0.403401389416555, 0.40348330983776004, 0.40356485969171596, 0.4036460419756539, 0.403726859652002, 0.4038073156489115, 0.4038874128607722, 0.4039671541487186, 0.404046542341128, 0.40412558023410694, 0.40420427059197106, 0.404282616147715, 0.4043606196034738, 0.4044382836309769, 0.4045156108719925, 0.4045926039387647, 0.4046692654144436, 0.40474559785350533, 0.4048216037821678, 0.40489728569879607, 0.40497264607430294, 0.4050476873525402, 0.4051224119506854, 0.40519682225961995, 0.4052709206443015, 0.4053447094441296, 0.4054181909733051, 0.4054913675211836, 0.40556424135262203, 0.40563681470831997, 0.4057090898051553, 0.4057810688365128, 0.4058527539726092, 0.40592414736081095, 0.40599525112594737, 0.4060660673706188, 0.4061365981754987, 0.40620684559963155, 0.40627681168072527, 0.40634649843543924, 0.4064159078596667, 0.40648504192881385, 0.4065539025980726, 0.40662249180269044, 0.4066908114582347, 0.4067588634608539, 0.4068266496875326, 0.4068941719963449, 0.4069614322267013, 0.4070284321995935, 0.40709517371783344, 0.4071616585662909, 0.4072278885121248, 0.4072938653050125, 0.4073595906773746, 0.4074250663445966, 0.40749029400524694, 0.40755527534129177, 0.40762001201830567, 0.4076845056856803, 0.40774875797682847, 0.40781277050938575, 0.4078765448854094, 0.40794008269157295, 0.4080033854993584, 0.4080664548652468, 0.40812929233090306, 0.40819189942336054, 0.4082542776552017, 0.4083164285247358, 0.4083783535161748, 0.4084400540998052, 0.4085015317321591, 0.4085627878561807, 0.4086238239013923, 0.40868464128405657, 0.40874524140733615, 0.4088056256614518, 0.40886579542383805, 0.4089257520592958, 0.4089854969201435, 0.4090450313463661, 0.4091043566657605, 0.4091634741940811, 0.4092223852351811, 0.40928109108115346, 0.40933959301246786, 0.40939789229810836, 0.40945599019570605, 0.4095138879516725, 0.40957158680132916, 0.40962908796903685, 0.40968639266832146, 0.409743502101999, 0.40980041746229956, 0.40985713993098705, 0.40991367067948037, 0.4099700108689703, 0.41002616165053674, 0.41008212416526213, 0.4101378995443456, 0.4101934889092142, 0.4102488933716324, 0.41030411403381084, 0.41035915198851347, 0.41041400831916236, 0.41046868409994264, 0.4105231803959041, 0.41057749826306267, 0.4106316387485009, 0.41068560289046535, 0.4107393917184643, 0.41079300625336346, 0.4108464475074804, 0.41089971648467766, 0.4109528141804553, 0.4110057415820405, 0.4110584996684784, 0.4111110894107197, 0.4111635117717077, 0.4112157677064645, 0.41126785816217665, 0.41131978407827735, 0.4113715463865303, 0.41142314601111096, 0.41147458386868674, 0.4115258608684971, 0.41157697791243103, 0.41162793589510543, 0.411678735703941, 0.41172937821923733, 0.41177986431424785, 0.4118301948552534, 0.4118803707016343, 0.411930392705942, 0.4119802617139701, 0.41202997856482393, 0.41207954409098935, 0.4121289591184011, 0.41217822446650965, 0.4122273409483476, 0.41227630937059506, 0.4123251305336447, 0.41237380523166534, 0.4124223342526646, 0.4124707183785519, 0.4125189583851996, 0.41256705504250346, 0.4126150091144433, 0.4126628213591415, 0.41271049252892195, 0.4127580233703677, 0.41280541462437803, 0.4128526670262248, 0.4128997813056083, 0.412946758186712, 0.412993598388257, 0.4130403026235559, 0.4130868716005658, 0.41313330602194, 0.4131796065850809, 0.41322577398219024, 0.41327180890032017, 0.413317712021423, 0.4133634840224, 0.41340912557515114, 0.4134546373466225, 0.41350001999885394, 0.41354527418902676, 0.4135904005695091, 0.4136353997879027, 0.4136802724870884, 0.41372501930526984, 0.41376964087601903, 0.4138141378283198, 0.4138585107866106, 0.4139027603708283, 0.4139468871964492, 0.4139908918745318, 0.41403477501175806, 0.41407853721047394, 0.4141221790687295, 0.4141657011803197, 0.41420910413482304, 0.4142523885176411, 0.41429555491003683, 0.4143386038891729, 0.4143815360281488, 0.41442435189603904, 0.4144670520579295, 0.4145096370749535, 0.4145521075043284, 0.41459446389939136, 0.41463670680963355, 0.41467883678073625, 0.4147208543546045, 0.4147627600694011, 0.4148045544595808, 0.4148462380559234, 0.41488781138556635, 0.4149292749720378, 0.4149706293352885, 0.4150118749917239, 0.41505301245423515, 0.41509404223223106, 0.41513496483166834, 0.4151757807550821, 0.4152164905016166, 0.415257094567054, 0.41529759344384515, 0.4153379876211374, 0.41537827758480494, 0.415418463817476, 0.41545854679856226, 0.4154985270042858, 0.41553840490770766, 0.4155781809787543, 0.41561785568424536, 0.4156574294879201]
belief_array_25 = [0.5, 0.45, 0.3778679628856705, 0.3128679730661058, 0.21566308576419618, 0.15103499428156042, 0.13218407511266284, 0.13388649900392274, 0.1285734575712704, 0.13153738546998128, 0.12431021211284876, 0.12592512911097156, 0.11706100410155189, 0.11784547547166406, 0.11990546070566203, 0.12198788199175654, 0.12392861554705852, 0.12572329806633104, 0.12738759446522332, 0.12893721196574776, 0.13038559879041878, 0.13174408494427658, 0.13302226091931196, 0.13422830602629482, 0.1353692476047294, 0.13645116441456367, 0.13747934749025764, 0.13845842858268073, 0.13939248367245036, 0.14028511711151329, 0.1411395305625066, 0.14195857989858124, 0.14274482248732268, 0.1435005567338316, 0.14422785534654226, 0.14492859347765447, 0.1456044726517715, 0.14625704121260816, 0.1468877118748323, 0.14749777685626875, 0.14808842097749103, 0.14866073304579025, 0.14921571578454923, 0.14975429452406835, 0.15027732483352024, 0.15078559924415796, 0.1512798531897539, 0.1517607702704243, 0.15222898692964892, 0.1526850966207508, 0.15312965352783875, 0.1535631758968028, 0.15398614902406565, 0.15439902794415206, 0.1548022398515303, 0.15519618628742854, 0.15558124511828736, 0.15595777232906408, 0.15632610365165545, 0.1566865560461781, 0.15703942905066665, 0.1573850060128747, 0.15772355521623888, 0.15805533091065752, 0.158380574257513, 0.1586995141972986, 0.15901236824728074, 0.15931934323581176, 0.15962063597919435, 0.15991643390636912, 0.16020691563614542, 0.16049225151120555, 0.16077260409268312, 0.16104812861873208, 0.16131897343016544, 0.1615852803659415, 0.16184718513100585, 0.16210481763876067, 0.16235830233021664, 0.1626077584716946, 0.16285330043277066, 0.16309503794600722, 0.16333307634987226, 0.16356751681612808, 0.16379845656285608, 0.1640259890541857, 0.16425020418770422, 0.16447118847044054, 0.16468902518424378, 0.1649037945413084, 0.16511557383053754, 0.16532443755537884, 0.16553045756371948, 0.1657337031703775, 0.16593424127268763, 0.16613213645963965, 0.16632745111499303, 0.16652024551475952, 0.16671057791941668, 0.16689850466118689, 0.16708408022669435, 0.16726735733528775, 0.16744838701329645, 0.16762721866446967, 0.16780390013682978, 0.16797847778615466, 0.16815099653629, 0.16832149993647766, 0.1684900302158755, 0.16865662833542885, 0.1688213340372477, 0.16898418589162933, 0.16914522134186005, 0.16930447674691912, 0.16946198742220075, 0.16961778767836366, 0.1697719108584082, 0.1699243893730784, 0.1700752547346765, 0.17022453758937528, 0.17037226774810638, 0.1705184742160985, 0.1706631852211365, 0.17080642824060427, 0.17094823002737605, 0.17108861663461222, 0.17122761343951476, 0.17136524516609458, 0.17150153590699796, 0.1716365091444398, 0.1717701877702848, 0.1719025941053196, 0.17203374991775294, 0.17216367644098068, 0.17229239439065097, 0.1724199239810612, 0.1725462849409179, 0.17267149652848934, 0.1727955775461777, 0.17291854635453802, 0.17304042088576777, 0.17316121865669137, 0.17328095678126187, 0.1733996519826006, 0.17351732060459585, 0.17363397862307867, 0.17374964165659468, 0.17386432497678922, 0.1739780435184215, 0.17409081188902442, 0.17420264437822414, 0.17431355496673376, 0.17442355733503523, 0.1745326648717609, 0.1746408906817885, 0.17474824759405994, 0.174854748169136, 0.17496040470649699, 0.17506522925159923, 0.17516923360269765, 0.1752724293174434, 0.1753748277192651, 0.17547643990354206, 0.17557727674357798, 0.1756773488963826, 0.17577666680826778, 0.17587524072026672, 0.1759730806733809, 0.17607019651366324, 0.176166597897142, 0.17626229429459206, 0.1763572949961591, 0.17645160911584196, 0.1765452455958379, 0.17663821321075712, 0.17673052057170927, 0.17682217613026802, 0.17691318818231766, 0.1770035648717848, 0.17709331419426178, 0.17718244400052213, 0.17727096199993492, 0.17735887576377957, 0.17744619272846546, 0.1775329201986588, 0.17761906535032107, 0.17770463523366098, 0.17778963677600296, 0.17787407678457562, 0.17795796194922225, 0.17804129884503628, 0.17812409393492362, 0.1782063535720952, 0.17828808400249083, 0.17836929136713786, 0.17844998170444543, 0.17853016095243754, 0.17860983495092603, 0.17868900944362615, 0.17876769008021548, 0.17884588241833904, 0.17892359192556193, 0.17900082398127048, 0.1790775838785248, 0.17915387682586265, 0.17922970794905774, 0.17930508229283243, 0.1793800048225273, 0.1794544804257278, 0.1795285139138511, 0.17960211002369125, 0.17967527341892792, 0.1797480086915958, 0.1798203203635188, 0.17989221288770857, 0.1799636906497284, 0.18003475796902474, 0.18010541910022548, 0.1801756782344074, 0.1802455395003329, 0.18031500696565728, 0.18038408463810712, 0.18045277646663083, 0.18052108634252179, 0.18058901810051528, 0.18065657551985992, 0.18072376232536347, 0.1807905821884152, 0.1808570387279841, 0.18092313551159422, 0.18098887605627795, 0.181054263829507, 0.18111930225010298, 0.18118399468912688, 0.1812483444707486, 0.18131235487309727, 0.18137602912909218, 0.18143937042725566, 0.18150238191250778, 0.1815650666869434, 0.18162742781059243, 0.1816894683021636, 0.18175119113977128, 0.1818125992616476, 0.18187369556683858, 0.18193448291588538, 0.18199496413149086, 0.18205514199917242, 0.18211501926790047, 0.18217459865072338, 0.18223388282538006, 0.1822928744348985, 0.18235157608818264, 0.18240999036058697, 0.18246811979447874, 0.18252596689978928, 0.18258353415455308, 0.18264082400543685, 0.18269783886825688, 0.18275458112848664, 0.18281105314175328, 0.182867257234325, 0.18292319570358812, 0.1829788708185145, 0.18303428482011996, 0.18308943992191368, 0.183144338310338, 0.18319898214520064, 0.18325337356009747, 0.18330751466282735, 0.18336140753579927, 0.1834150542364309, 0.18346845679753992, 0.18352161722772753, 0.18357453751175484, 0.18362721961091205, 0.1836796654633801, 0.1837318769845861, 0.18378385606755185, 0.18383560458323533, 0.18388712438086657, 0.18393841728827653, 0.18398948511222013, 0.18404032963869332, 0.18409095263324424, 0.18414135584127855, 0.18419154098835938, 0.18424150978050124, 0.18429126390445927, 0.1843408050280127, 0.18439013480024358, 0.18443925485180984, 0.18448816679521424, 0.18453687222506784, 0.18458537271834913, 0.18463366983465823, 0.18468176511646708, 0.18472966008936448, 0.1847773562622974, 0.18482485512780794, 0.18487215816226582, 0.18491926682609716, 0.18496618256400904, 0.18501290680521032, 0.18505944096362872, 0.18510578643812375, 0.1851519446126963, 0.1851979168566948, 0.18524370452501743, 0.1852893089583112, 0.18533473148316743, 0.1853799734123144, 0.18542503604480584, 0.1854699206662073, 0.1855146285487787, 0.1855591609516542, 0.18560351912101875, 0.1856477042902817, 0.18569171768024847, 0.1857355604992877, 0.1857792339434972, 0.18582273919686654, 0.18586607743143668, 0.18590924980745777, 0.1859522574735436, 0.1859951015668242, 0.18603778321309555, 0.18608030352696697, 0.18612266361200636, 0.18616486456088283, 0.18620690745550722, 0.18624879336717048, 0.1862905233566795, 0.18633209847449128, 0.18637351976084443, 0.18641478824588942, 0.18645590494981568, 0.18649687088297773, 0.18653768704601892, 0.18657835442999293, 0.18661887401648433, 0.18665924677772602, 0.18669947367671608, 0.1867395556673319, 0.18677949369444322, 0.18681928869402287, 0.18685894159325658, 0.18689845331065014, 0.18693782475613588, 0.186977056831177, 0.18701615042887043, 0.1870551064340483, 0.18709392572337769, 0.18713260916545918, 0.18717115762092346, 0.1872095719425269, 0.187247852975246, 0.18728600155636937, 0.18732401851558955, 0.187361904675093, 0.18739966084964835, 0.18743728784669417, 0.1874747864664248, 0.18751215750187558, 0.1875494017390061, 0.18758651995678277, 0.18762351292726, 0.18766038141566044, 0.18769712618045387, 0.18773374797343478, 0.18777024753979948, 0.18780662561822128, 0.18784288294092544, 0.18787902023376246, 0.18791503821628042, 0.18795093760179676, 0.18798671909746856, 0.188022383404362, 0.1880579312175208, 0.18809336322603393, 0.18812868011310224, 0.1881638825561039, 0.18819897122665963, 0.18823394679069622, 0.18826880990850964, 0.1883035612348274, 0.18833820141886976, 0.18837273110441025, 0.1884071509298352, 0.18844146152820293, 0.18847566352730144, 0.18850975754970606, 0.1885437442128357, 0.18857762412900891, 0.1886113979054985, 0.18864506614458632, 0.1886786294436164, 0.1887120883950481, 0.1887454435865083, 0.1887786956008426]


##plt.scatter(range(100), belief_array_75[0:100])
plt.plot(range(100), belief_array_75[0:100], label = "mu=0.75")

##plt.scatter(range(100), belief_array_50[0:100])
plt.plot(range(100), belief_array_50[0:100], label = "mu=0.5")

##plt.scatter(range(100), belief_array_25[0:100])
plt.plot(range(100), belief_array_25[0:100], label = "mu=0.25")



plt.ylim(0.05, 0.84)

##plt.title("Overall shared beliefs")
plt.legend(loc='upper right')
plt.savefig("Overall_beliefs"+ ".png")
plt.show()

x = 5
def test():
  print (x)

for i in range(5):
  test()
  x += 1

# # !pip install netgraph
# # !sudo apt-get install graphviz graphviz-dev
# # !pip install pygraphviz
# import networkx as nx
# from netgraph import Graph
# import pygraphviz as pgv
# from networkx.drawing import nx_pydot
# from graphviz import Source

# def weighted_graph():
#   pass
#   G = nx.MultiDiGraph()

#   nodes = np.arange(0, len(agents)).tolist()
  
#   G.add_nodes_from(nodes)

#   edges = []

#   for i in range(len(agents)):
#     for j in range(len(agents)):
#       if i != j: edges.append((i,j))

#   # G = pgv.AGraph(directed=True, strict=True, rankdir="LR")

#   agent_labels = {}
#   i = 0
#   for agent in agents:
#     agent_labels[i] = agent
#     i+=1
  
#   # for agent in agents:
#   #   for n in agents:
#   #     if agent == n: continue
#   #     G.add_edge(agent_labels[agent], agent_labels[n])
#   #     # pass
      
  
#   G.add_edges_from(edges)

#   edge_labels = {}

#   for e in edges:
#     agent = agent_labels[e[0]]
#     neighbor = agent_labels[e[1]]
#     edge_labels[e] = str('%.4f' % agent.beliefs[neighbor])


#   labels = {i : "agent " + str(i) for i in range(len(agents))}

#   pos = nx.spring_layout(G, k=0.2*1/np.sqrt(len(G.nodes())), iterations=20)

#   # nx.draw_networkx(G, labels = labels, 
#   #                  arrows = True, 
#   #                  node_size = 1000)
#   # nx.draw_networkx_edge_labels(G, pos = pos,
#   #                            edge_labels = edge_labels)
#   # plt.figure(figsize=(20 , 20))
#   # netgraph.draw(G, labels = labels, arrows = True, node_size=1000)

#   # plt.show()

#   # plt.show()
#   nx_pydot.write_dot(G, 'multig.dot')
#   A = pgv.AGraph("multig.dot")
#   A.layout("dot")
#   A.draw("foo.png")
#   # Source.from_file('multig.dot')


#   # G = nx.DiGraph()

#   # G.add_edge('1','2')
#   # G.add_edge('1','3')
#   # G.add_edge('3','2')
#   # G.add_edge('3','4')
#   # G.add_edge('4','3')

#   # plot_instance = Graph(G, node_color='w', edge_color='k', edge_width=2.0, node_labels=labels)
 

#   # # plot_instance = Graph(
#   # #   G, node_size=5,
#   # #   node_labels=True, node_label_offset=0.1, node_label_fontdict=dict(size=20),
#   # #   edge_width=2,
#   # #   arrows=True)
#   # plt.show()


#   # G.add_nodes_from(agent_labels.values())
#   # # G.add_edges_from(edges)

#   # G.graph_attr["epsilon"] = "0.01"
#   # print(G.string())
#   # G.layout("dot")
#   # G.draw("foo.png")

# # weighted_graph()

d = {1:3,4:6}
ar = np.asarray(d.values())
print (list(d.keys())[1])
len(d)

a = np.array([4])
print (a)
a.shape
